# spark-radar
In radar, we design a new scheduler based on tasks' size and node capability. Traditional locality-aware scheduler is not suitable for heterogeneous tasks and shared clusters. We propose to add two eyes for scheduler. One is tasks' size which we can get from HDFS. Another is node's capability which we can get by exploiting the recurring characteristics of spark streaming batches. We make scheduling decisions according to the following principles: (1) large task first which we can amortize the large tasks' impact on stage execution time through multi waves, (2) fast nodes large tasks and slow nodes small tasks which we can achieve better load balancing, (3) choose task in corresponding location of node capability order for this node. By doing so, we can avoid 86.57% speculative tasks, lower 20.96% latency and save about 10% resources in Tencent production clusters.
